# Penn Treebank Language Modeling Configuration - Colab Quick Test
# Optimized for 5-minute GPU test on Google Colab

# Model Configuration (Smaller for quick testing)
model:
  type: "LSTM"  
  vocab_size: 18057   # Updated to recommended vocabulary size from analysis
  embedding_dim: 256  # Smaller for speed
  hidden_dim: 256     # Smaller for speed
  num_layers: 2       # Fewer layers for speed
  dropout: 0.3
  tie_weights: true

# Training Configuration (Quick test)
training:
  batch_size: 128     # Larger batch for GPU
  sequence_length: 38 # Updated based on analysis recommendations
  learning_rate: 0.001
  max_epochs: 3       # Just 3 epochs for quick test
  gradient_clip: 1.0
  patience: 2
  warmup_steps: 500
  
# Data Configuration
data:
  data_dir: "data/ptb"
  train_file: "ptb.train.txt"
  valid_file: "ptb.valid.txt"
  test_file: "ptb.test.txt"
  min_freq: 3         # Updated to match vocabulary builder
  max_vocab_size: 20000 # Increased to accommodate actual vocab size
  
# Logging and Checkpoints
logging:
  log_interval: 50    # More frequent logging
  save_dir: "checkpoints"
  tensorboard_dir: "runs"
  save_best_only: true
  
# Evaluation
evaluation:
  eval_batch_size: 128
  eval_interval: 1
  
# Advanced Training Options
advanced:
  use_scheduler: true
  scheduler_type: "cosine"
  weight_decay: 1e-6
  label_smoothing: 0.0
